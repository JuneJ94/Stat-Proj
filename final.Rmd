---
title: 'STAT 420: Final Project Report'
authors: "Team"
output:
  html_document:
    theme: readable
    toc: yes
  pdf_document:
    toc: yes
---



##  Installing packages (commented out) and loading libraries for future use.
```{r}
#install.packages("mltools")
#install.packages("caret")
#install.packages("dplyr")
#install.packages("ggplots2")
#install.packages('DT')
library(mltools)
library(data.table)
library(knitr)
library(dplyr)
library(ggplot2)
library(caret)
library(faraway)
library(lmtest)
library(MASS)
library(DT)
```

## Data Processing

**Loading dataset in R from the CSV file, and removing some columns which are not needed**
```{r}
car_data = read.csv("Cars_data.csv")
car_data = subset(car_data, select = -c(Vehicle.Style, Market.Category))
car_data = na.omit(car_data)
#unique(car_data$Transmission.Type)
#colnames(car_data)
#unique(car_data$Engine.Fuel.Type)
#unique(car_data$Driven_Wheels)
unique(car_data$Vehicle.Size)
#car_data$Make<-NULL
car_data$Model<- NULL
car_data_info = car_data
#head(car_data)
colnames(car_data_info)
```


## Dataset Overview:

**The dataset car_data now contains the following variables:**

**Make** - The car brand

**Year** - The year the car model was released

**Engine.Fuel.Type** - The Fuel which the car runs on

**Engine.HP** - The standard measure of power of the car's engine

**Engine.Cylinders** - Number of Cylinders in the engine of the car

**Transmission.Type** - Specifies the transmission type, self explanatory

**Driven_Wheels** - Specifies to which wheels the car sends power

**Number.of.Doors** - Number of doors in the car - self explanatory

**Vehicle.Size** - Specifies the size of the car - compact, midsize, large

**highway.MPG** - Estimated miles per gallon the car travels on the highway

**city.mpg** - Estimated miles per gallon the car travels in the city

**Popularity** - Value assigned based on Twitter scraping - is part of the original dataset

**MSRP** - The response in our model. It stands for Manufacturer's Suggested Retail Price.




## Engineering the data

```{r}
hist( car_data$MSRP, scien = FALSE, col = "lightblue")
```


**Removing extreme prices less than $10,000 and greater than $100,000**

We decided to do this since there were certain extreme outliers as visible in the graph above. 
```{r}
car_data_priced<-car_data[!(car_data$MSRP>100000 | car_data$MSRP< 10000 ),]
range(car_data_priced$MSRP)
```


Once this is done, the MSRP Histogram looks like:

```{r}
hist( car_data_priced$MSRP, scientific = FALSE, col = "lightpink")
```

This is a reasonable distribution for our response variable. Additionally, price is a much more important factor in the mass market than in the expensive/luxury segment so it is reasonable to restrict the price at $100,000. In fact, it may even be brought down further. -  https://smallbusiness.chron.com/price-sensitivity-product-65805.html



**Removing the non automatic/manual transmission types, and storing this new data in car_data_transd dataframe**

This is done for simplicity. There are very few automobiles with non automatic/manual transmissions, so our model would not be accurate at predicting these even if we retained these values.

```{r}
car_data_transd<-car_data_priced[!(car_data_priced$Transmission.Type=="AUTOMATED_MANUAL" | car_data_priced$Transmission.Type=="DIRECT_DRIVE" | car_data_priced$Transmission.Type=="UNKNOWN"),]
unique(car_data_transd$Transmission.Type)
```



**Removing certain fuel types, keeping only gasoline and diesel. Storing the result in car_data_fuel dataframe**

This is once again done for simplicity when it comes to predictors. We have a large dataset, so we can afford to omit certain types of automobiles. Additionally, since there were only few of non gasoline/diesel vehicles and we are targeting the mass market, this makes sense. We understand that the electric car segment is growing, and a more up-to-date dataset (this one spans all the way from 1990 to 2017) would help us cater to that market.

```{r}
car_data_fuel<-car_data_transd[!(grepl("flex", car_data_transd$Engine.Fuel.Type, fixed = TRUE)
|car_data_transd$Engine.Fuel.Type=="electric" | car_data_transd$Engine.Fuel.Type=="" | car_data_transd$Engine.Fuel.Type=="natural gas"),]
unique(car_data_fuel$Engine.Fuel.Type)
```


**Assigning the different types of gasoline to a single "gasoline value". Now, the only two values for fuel type will be "gasoline" and "diesel" as visible below**

Here, we combine the different types of gasoline into one.

```{r}
car_data_fuel$Engine.Fuel.Type[car_data_fuel$Engine.Fuel.Type == "premium unleaded (required)" ] <- "gasoline"
car_data_fuel$Engine.Fuel.Type[car_data_fuel$Engine.Fuel.Type == "regular unleaded" ] <- "gasoline"
car_data_fuel$Engine.Fuel.Type[car_data_fuel$Engine.Fuel.Type == "premium unleaded (recommended)" ] <- "gasoline"
unique(car_data_fuel$Engine.Fuel.Type)
```



#### Making categorical variables factors, and adding age variable

**The age variable is essentially how many years ago the model was released. It is the "Year" in the dataset subtracted from the current year**
```{r}
car_data_factored = car_data_fuel
car_data_factored$Vehicle.Size <- factor(car_data_factored$Vehicle.Size)
car_data_factored$Transmission.Type <- factor(car_data_factored$Transmission.Type)
car_data_factored$Engine.Fuel.Type <- factor(car_data_factored$Engine.Fuel.Type)
car_data_factored$Driven_Wheels <- factor(car_data_factored$Driven_Wheels)
car_data_factored$Engine.Cylinders <- factor(car_data_factored$Engine.Cylinders)
car_data_factored$Number.of.Doors <- factor(car_data_factored$Number.of.Doors)
car_data_factored$Make <- factor(car_data_factored$Make)
levels(car_data_factored$Vehicle.Size)
levels(car_data_factored$Transmission.Type)
levels(car_data_factored$Engine.Fuel.Type)
levels(car_data_factored$Driven_Wheels)
levels(car_data_factored$Engine.Cylinders)
levels(car_data_factored$Number.of.Doors)
levels(car_data_factored$Make)
#car_data_factored = one_hot(as.data.table(car_data_factored))
car_data_factored$ReleasedYearsAgo <- with(car_data_factored, 2020 - Year)
```

**Removing repetitive/unnecessary variable(s)**

```{r}
car_data_factored$Year <- NULL
```


## Modeling


**Simple additive models:**
```{r}
set.seed(100)
#train-test  split using 65% of the data
samplesize = round(0.65*nrow(car_data_factored), 0)
index = sample(seq_len(nrow(car_data_factored)), size = samplesize)
data_train = car_data_factored[index,]
data_test = car_data_factored[-index,]
msrp_mod_additive = lm(MSRP ~. , data_train)
summary(msrp_mod_additive)$r.sq
msrp_mod2 = lm(MSRP ~ highway.MPG + Popularity, data_test)
#summary(msrp_mod2)
#anova(msrp_mod2, msrp_mod)
```
```{r}
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
```



**We get a fairly high value for Adjusted R. Squared, which is encouraging. We now consider some other models as well**



**Creating Quadratic Model with AIC Step**
```{r}
MSRP_big_mod_poly = lm(
  MSRP ~ . + I(Engine.HP ^ 2) + I(ReleasedYearsAgo ^ 2) + I(city.mpg ^ 2) + I(highway.MPG ^ 2)  + I(Popularity ^ 2), 
  data = data_train)
MSRP_mod_both_aic_poly = step(MSRP_big_mod_poly, direction = "both", trace = 0)
```



**Creating Linear Model with AIC Step**
```{r}
#hipcenter_mod_both_aic = step(
  #hipcenter_mod_start, 
  #scope = hipcenter ~ Age + Weight + HtShoes + Ht + Seated + Arm + Thigh + Leg, 
  #direction = "both")
MSRP_big_mod_linear = lm(
  MSRP ~ . , 
  data = data_train)
MSRP_mod_both_aic_lin = step(MSRP_big_mod_linear, direction = "both", trace = 0)
summary(MSRP_mod_both_aic_lin)$r.sq
```


```{r}
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
```

**Creating Linear Model with BIC Step**

```{r}
msrp_mod_start = lm(MSRP ~ ., data = data_train)
n = length(resid(msrp_mod_start))
msrp_mod_linear_both_bic = step(msrp_mod_start, direction = "both", k = log(n), trace = 0)
```


**Creating Quadratic Model with BIC Step**

```{r}
msrp_mod_start2 = lm(MSRP ~ . + I(Engine.HP^2)  + I(city.mpg^2) + I(highway.MPG^2) + I(Popularity^2) - I( ReleasedYearsAgo^2), data = data_train)
n = length(resid(msrp_mod_start2))
msrp_mod_poly_both_bic = step( msrp_mod_start2, direction = "both", k = log(n), trace = 0)
```




**Metric Table: **

```{r}
to_insert_1 = c("msrp_mod_additive", calc_loocv_rmse(msrp_mod_additive), 
                summary(msrp_mod_additive)$adj.r.sq, summary(msrp_mod_additive)$r.sq)
to_insert_2 = c("MSRP_mod_both_aic_lin", calc_loocv_rmse(MSRP_mod_both_aic_lin) ,summary(MSRP_mod_both_aic_lin)$adj.r.sq,summary(MSRP_mod_both_aic_lin)$r.sq )
to_insert_3 = c("MSRP_mod_both_aic_poly", calc_loocv_rmse(MSRP_mod_both_aic_poly) ,summary(MSRP_mod_both_aic_poly)$adj.r.sq,summary(MSRP_mod_both_aic_poly)$r.sq )
to_insert_4 = c("msrp_mod_linear_both_bic", calc_loocv_rmse(msrp_mod_linear_both_bic) ,summary(msrp_mod_linear_both_bic)$adj.r.sq,summary(msrp_mod_linear_both_bic)$r.sq )
to_insert_5 = c("msrp_mod_poly_both_bic", calc_loocv_rmse(msrp_mod_poly_both_bic) ,summary(msrp_mod_poly_both_bic)$adj.r.sq,summary(msrp_mod_poly_both_bic)$r.sq )
dataframe.values = c(to_insert_1, to_insert_2, to_insert_3, to_insert_4, to_insert_5)
dataframe = matrix(dataframe.values,nrow=5 ,byrow = T)
colnames(dataframe) = c("Model Name","calc_loocv_rmse","Adj. R-Sq.", "R-Sq.")
datatable(dataframe)
```

```{r}
msrp_mod_additive$call
```


```{r}
MSRP_mod_both_aic_lin$call
```


```{r}
MSRP_mod_both_aic_poly$call
```


```{r}
msrp_mod_linear_both_bic$call
```

```{r}
msrp_mod_poly_both_bic$call
```


**We see that these are all fairly similar models, and the two which are somewhat different are MSRP_mod_both_aic_poly and msrp_mod_poly_both_bic These two consistently give marginally better values for the metrics. We choose to pursue the model MSRP_mod_both_aic_poly for now since it uses an extra variable and has a very slightly better standing metric-wise.**







**Assumptions**


```{r}
plot_func = function(model, pointcol = "blue",linecol = "green") {
  plot(fitted(model), resid(model), col = pointcol, pch = 20, xlab = "Fitted", ylab = "Residuals")
  abline(h = 0, col = linecol, lwd = 2)
}
```

```{r}
assumption_tester = function(model) {
  
  qqnorm(resid(model), main = "Normal Q-Q Plot", col = "darkgrey")
  qqline(resid(model), col = "dodgerblue", lwd = 2)
  
  #normality test
  print("Shapiro test:")
  print(shapiro.test(resid(model)[0:5000]))
  hist(model$resid)
  
  #multicollinearity
  vif_vals = vif(model)
  print("Max VIF Value:")
  print(max(vif_vals))
  print(vif_vals[vif_vals > 10])
  
  #Constant Variance
  plot_func(model)
  
  print("Breusch-Pagan test:")
  print(bptest(model))
  
  print("Adjusted R-Squared:")
  print(summary(model)$r.sq)
  
  
}
```



```{r}
#assumption_tester(msrp_mod)
```


**Here, we can see that the VIF values for Engine.Cylinders and highway.MPG are fairly high if we go with a threshold of 10. There does appear to be some multicollinearity **

**The Shapiro-Wilk test and the qq plot also indicate non-normality**

**The constant variance assumption (based on the fitted vs residuals graph and the BP-test) also does appear to be violated **



## Managing Assumption Violations

### Multicollinearity

**We can look into removing the Engine.Cylinders variable and seeing how this impacts the model**

```{r}
msrp_mod_no_cyl = lm(MSRP ~. - Popularity - Engine.Cylinders, data_train)
vif(msrp_mod_no_cyl)[vif(msrp_mod_no_cyl) > 10]
```


**We can further considering removing highway.MPG , since this issue is probably being caused by the highway.MPG and city.mpg being closely related**

```{r}
msrp_mod_no_cyl_highmpg = lm(MSRP ~. - Popularity - Engine.Cylinders - highway.MPG, data_train)
vif(msrp_mod_no_cyl_highmpg)[vif(msrp_mod_no_cyl_highmpg) > 5]
```


**Now, we can see that none of the VIFs are more than 5, which is well below the threshold.**


```{r}
assumption_tester(msrp_mod_no_cyl_highmpg)
```
**We see that we have given up on some prediction accuracy in order to satisfy the model assumption**


## Influential Points:

We can consider removing influential points from our model

```{r}
msrp_mod_no_cyl_highmpg_cd = cooks.distance(msrp_mod_no_cyl_highmpg)
msrp_mod_influential_fix = lm(MSRP ~. - Popularity - Engine.Cylinders - highway.MPG, data = data_train, 
                              subset = msrp_mod_no_cyl_highmpg_cd <= 4/length(msrp_mod_no_cyl_highmpg_cd))
assumption_tester(msrp_mod_influential_fix)
```

**This has marginally helped our value of adjusted R-squared, which is once more encouraging**


**In order to work towards the normality assumption and the multicollinearity, we will need to consider transformations on our predictors and our response variables**


## Transformations

**Since our response variable (MSRP) is strictly positive, we can consider Box-Cox transformations**
```{r}
boxcox(msrp_mod_influential_fix, plotit = TRUE, lambda = seq(0.1, 0.3, by = 0.1))
```


```{r}
msrp_mod_cox = lm((((MSRP ^ 0.2) - 1) / 0.2) ~ .  - Popularity - Engine.Cylinders - highway.MPG, data = data_train, 
                              subset = msrp_mod_no_cyl_highmpg_cd <= 4/length(msrp_mod_no_cyl_highmpg_cd))
msrp_mod_log = lm(log(MSRP) ~ .  - Popularity - Engine.Cylinders - highway.MPG, data = data_train, 
                              subset = msrp_mod_no_cyl_highmpg_cd <= 4/length(msrp_mod_no_cyl_highmpg_cd))
```


```{r}
assumption_tester(msrp_mod_log)
```



```{r}
assumption_tester(msrp_mod_cox)
```



**Trying Polynomial Model with AIC choice**
```{r}
MSRP_big_mod = lm(
  MSRP ~ . + I(Engine.HP ^ 2) + I(ReleasedYearsAgo ^ 2) + I(city.mpg ^ 2) + I(highway.MPG ^ 2)  + I(Popularity ^ 2), 
  data = data_train)
MSRP_mod_back_aic = step(MSRP_big_mod, direction = "backward", trace = 0)
summary(MSRP_mod_back_aic)
```





```{r}
#assumption_tester(MSRP_big_mod)
```


```{r}
#alias(MSRP_mod_back_aic)
#assumption_tester(MSRP_mod_back_aic)
```



**Making model improvements**

```{r}
car_removed_predictors = lm(log(MSRP) ~ Make + Engine.Fuel.Type + log(Engine.HP) +  Transmission.Type + 
    Driven_Wheels + Number.of.Doors + 
    I(ReleasedYearsAgo^2) + I(city.mpg^2) + 
    I(highway.MPG^2) , data = data_train)
```

```{r}
assumption_tester(car_removed_predictors)
```

```{r}
alias(car_removed_predictors)
#summary(car_removed_predictors)
```






```{r}
#plot( MSRP~Engine.HP, data = car_data_factored, scientific = FALSE)
#hist( car_data_factored$MSRP, scientific = FALSE)
```



**This model does not **